---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "airbyte_connection Resource - terraform-provider-airbyte"
subcategory: ""
description: |-
  Connection resource
---

# airbyte_connection (Resource)

Connection resource

## Example Usage

```terraform
resource "airbyte_workspace" "test" {
  name = "test_workspace"
}

# Most basic possible example - custom sources/destinations with zero configuration
resource "airbyte_source_definition" "custom" {
  name              = "test_source_definition"
  docker_repository = "eabrouwer3/airbyte-test-data-source"
  docker_image_tag  = "0.0.1"
  documentation_url = "https://github.com/eabrouwer3/airbyte-test-data-source"
}

resource "airbyte_source" "custom" {
  definition_id            = airbyte_source_definition.custom.id
  workspace_id             = airbyte_workspace.test.id
  name                     = "test_source"
  connection_configuration = jsonencode({})
}

resource "airbyte_destination_definition" "custom" {
  name              = "test_destination_definition"
  docker_repository = "eabrouwer3/airbyte-test-data-destination"
  docker_image_tag  = "0.0.1"
  documentation_url = "https://github.com/eabrouwer3/airbyte-test-data-destination"
}

resource "airbyte_destination" "custom" {
  definition_id            = airbyte_destination_definition.custom.id
  workspace_id             = airbyte_workspace.test.id
  name                     = "test_destination"
  connection_configuration = jsonencode({})
}

data "airbyte_source_schema_catalog" "custom" {
  source_id = airbyte_source.custom.id
}

resource "airbyte_connection" "custom" {
  source_id      = airbyte_source.custom.id
  destination_id = airbyte_destination.custom.id
  status         = "active"
  sync_catalog   = data.airbyte_source_schema_catalog.custom.sync_catalog
}

# More complex E2E Testing setup with some custom configuration
resource "airbyte_source" "e2e" {
  # Find the definition_id for an existing source here https://github.com/airbytehq/airbyte/tree/master/airbyte-integrations/connectors
  # Look for metadata.yaml file, e.g. https://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/connectors/source-e2e-test/metadata.yaml
  definition_id = "d53f9084-fa6b-4a5a-976c-5b8392f4ad8a"
  workspace_id  = airbyte_workspace.test.id
  name          = "e2e_source"
  # Find the spec either in the docs for the connector
  # Or, find it here: https://github.com/airbytehq/airbyte/tree/master/airbyte-integrations/connectors
  # Look for src/main/resources/spec.json file, e.g. https://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/connectors/source-e2e-test/src/main/resources/spec.json
  connection_configuration = jsonencode({
    type = "CONTINUOUS_FEED"
    mock_catalog = {
      type               = "SINGLE_STREAM"
      stream_name        = "data_stream"
      stream_schema      = "{ \"type\": \"object\", \"properties\": { \"column1\": { \"type\": \"string\" } } }"
      stream_duplication = 1
    }
  })
}

resource "airbyte_destination" "e2e" {
  # Find the definition_id for an existing source here: https://github.com/airbytehq/airbyte/tree/master/airbyte-integrations/connectors
  # Look for metadata.yaml file, e.g. https://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/connectors/destination-e2e-test/metadata.yaml
  definition_id = "2eb65e87-983a-4fd7-b3e3-9d9dc6eb8537"
  workspace_id  = airbyte_workspace.test.id
  name          = "e2e_destination"
  # Find the spec either in the docs for the connector
  # Or, find it here: https://github.com/airbytehq/airbyte/tree/master/airbyte-integrations/connectors
  # Look for src/main/resources/spec.json file, e.g. https://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/connectors/destination-e2e-test/src/main/resources/spec.json
  connection_configuration = jsonencode({
    type = "LOGGING"
    logging_config = {
      logging_type    = "FirstN"
      max_entry_count = 100
    }
  })
}

data "airbyte_source_schema_catalog" "e2e" {
  source_id = airbyte_source.e2e.id
}

resource "airbyte_connection" "e2e" {
  name           = "E2E Testing Connection"
  source_id      = airbyte_source.e2e.id
  destination_id = airbyte_destination.e2e.id
  status         = "inactive"
  sync_catalog = [{
    source_schema = data.airbyte_source_schema_catalog.custom.sync_catalog.0.source_schema
    # Config some of the destination settings
    destination_config = merge(
      data.airbyte_source_schema_catalog.custom.sync_catalog.0.destination_config,
      {
        alias_name            = "data_stream_destination_alias"
        destination_sync_mode = "overwrite"
        sync_mode             = "full_refresh"
      }
    )
  }]
  # Set up a time schedule
  schedule_type = "basic"
  basic_schedule = {
    time_unit = "hours"
    units     = 24
  }
  # Add some special resource requirements
  resource_requirements = {
    cpu_request    = "0.5"
    cpu_limit      = "0.5"
    memory_request = "500Mi"
    memory_limit   = "500Mi"
  }
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `destination_id` (String) Destination ID
- `source_id` (String) Source ID
- `status` (String) Active means that data is flowing through the connection. Inactive means it is not.Deprecated means the connection is off and cannot be re-activated. The schema field describes the elements of the schema that will be synced. Allowed Values: 'active' | 'inactive' | 'deprecated'.
- `sync_catalog` (Attributes List) Describes the available schema (catalog). Each stream is split in two parts; the immutable schema from source and mutable configuration for destination. (see [below for nested schema](#nestedatt--sync_catalog))

### Optional

- `basic_schedule` (Attributes) Basic time schedule - "Run sync every ..." (see [below for nested schema](#nestedatt--basic_schedule))
- `cron_schedule` (Attributes) Flexible Cron Schedule (see [below for nested schema](#nestedatt--cron_schedule))
- `name` (String) Optional name of the connection
- `namespace_definition` (String) Method used for computing final namespace in destination. Allowed Values: 'source' | 'destination' | 'customformat'
- `namespace_format` (String) Used when namespaceDefinition is 'customformat'. If blank then behaves like namespaceDefinition = 'destination'. If "${SOURCE_NAMESPACE}" then behaves like namespaceDefinition = 'source'.
- `operation_ids` (List of String) Operation IDs
- `prefix` (String) Prefix that will be prepended to the name of each stream when it is written to the destination. Example: "airbyte_"
- `resource_requirements` (Attributes) Optional resource requirements to run workers (blank for unbounded allocations) (see [below for nested schema](#nestedatt--resource_requirements))
- `schedule_type` (String) Determine how the schedule data should be interpreted. Allowed: 'manual' | 'basic' | 'cron'
- `source_catalog_id` (String) Source Catalog ID

### Read-Only

- `breaking_change` (Boolean) Does this change constitute a breaking change
- `geography` (String) Allowed Values: 'auto' | 'us' | 'eu'
- `id` (String) Connection ID

<a id="nestedatt--sync_catalog"></a>
### Nested Schema for `sync_catalog`

Required:

- `destination_config` (Attributes) The mutable part of the stream to configure the destination (see [below for nested schema](#nestedatt--sync_catalog--destination_config))
- `source_schema` (Attributes) The immutable schema defined by the source (see [below for nested schema](#nestedatt--sync_catalog--source_schema))

<a id="nestedatt--sync_catalog--destination_config"></a>
### Nested Schema for `sync_catalog.destination_config`

Required:

- `destination_sync_mode` (String) Allowed Values: 'append' | 'overwrite' | 'append_dedup'
- `selected` (Boolean) Whether this config is selected i.e. should be synced
- `sync_mode` (String) Allowed Values: 'full_refresh' | 'incremental'

Optional:

- `alias_name` (String) Alias name to the stream to be used in the destination
- `cursor_field` (List of String) Path to the field that will be used to determine if a record is new or modified since the last sync. This field is REQUIRED if `sync_mode` is `incremental`. Otherwise it is ignored.
- `primary_key` (List of List of String) Paths to the fields that will be used as primary key. This field is REQUIRED if `destination_sync_mode` is `*_dedup`. Otherwise it is ignored.


<a id="nestedatt--sync_catalog--source_schema"></a>
### Nested Schema for `sync_catalog.source_schema`

Required:

- `name` (String) Stream's name

Optional:

- `default_cursor_field` (List of String) Path to the field that will be used to determine if a record is new or modified since the last sync. If not provided by the source, the end user will have to specify the comparable themselves.
- `json_schema` (String) Stream schema using json Schema specs
- `namespace` (String) Optional Source-defined namespace. Airbyte streams from the same sources should have the same namespace. Currently only used by JDBC destinations to determine what schema to write to.
- `source_defined_cursor` (Boolean) If the source defines the cursor field, then any other cursor field inputs will be ignored. If it does not, either the user_provided one is used, or the default one is used as a backup.
- `source_defined_primary_key` (List of List of String) If the source defines the primary key, paths to the fields that will be used as a primary key. If not provided by the source, the end user will have to specify the primary key themselves.
- `supported_sync_modes` (List of String) Allowed Values: 'full_refresh' | 'incremental'



<a id="nestedatt--basic_schedule"></a>
### Nested Schema for `basic_schedule`

Required:

- `time_unit` (String) Allowed: minutes | hours | days | weeks | months
- `units` (Number) Count of `time_unit`


<a id="nestedatt--cron_schedule"></a>
### Nested Schema for `cron_schedule`

Required:

- `cron_expression` (String) [Cron Expression](http://www.quartz-scheduler.org/documentation/quartz-2.3.0/tutorials/crontrigger.html). Example: `0 0 12 * * ?`.
- `cron_time_zone` (String) Time Zone to honor cron expression according to. Examples: `UTC`, `US/Denver`, etc.See the 'TZ database name' column [here](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones) for all options.


<a id="nestedatt--resource_requirements"></a>
### Nested Schema for `resource_requirements`

Optional:

- `cpu_limit` (String) CPU Limit
- `cpu_request` (String) CPU Requested
- `memory_limit` (String) Memory Limit
- `memory_request` (String) Memory Requested


